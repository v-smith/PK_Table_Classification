{
  "run_name": "trial-FFNN-classification",
  "tokenizer_file": "../tokenizers/tokenizerPKtablesSpecialTokens5000.json",
  "max_len": 500,
  "seq_len": 500,
  "num_classes":9,
  "epochs":50,
  "batch_size":64,
  "val_batch_size":64,
  "n_workers":0,
  "lr":0.01,
  "embeds_size":10,
  "stride": 10,
  "input_channels": 1,
  "out_channels": 1,
  "kernel_heights": [10,10,10]
}

